{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuedCpphhUjP",
        "outputId": "e0ed9142-8d4f-483e-bfcc-be07d2a7988d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 21.5MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 336kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 6.12MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Test Loss: 0.0028, Accuracy: 86.96%\n",
            "Epoch 2: Test Loss: 0.0024, Accuracy: 89.01%\n",
            "Epoch 3: Test Loss: 0.0022, Accuracy: 89.98%\n",
            "Epoch 4: Test Loss: 0.0021, Accuracy: 90.40%\n",
            "Epoch 5: Test Loss: 0.0020, Accuracy: 90.48%\n",
            "Epoch 6: Test Loss: 0.0019, Accuracy: 91.27%\n",
            "Epoch 7: Test Loss: 0.0019, Accuracy: 91.41%\n",
            "Epoch 8: Test Loss: 0.0018, Accuracy: 91.72%\n",
            "Epoch 9: Test Loss: 0.0017, Accuracy: 92.04%\n",
            "Epoch 10: Test Loss: 0.0017, Accuracy: 92.18%\n",
            "Epoch 11: Test Loss: 0.0018, Accuracy: 92.14%\n",
            "Epoch 12: Test Loss: 0.0017, Accuracy: 92.31%\n",
            "Epoch 13: Test Loss: 0.0017, Accuracy: 92.04%\n",
            "Epoch 14: Test Loss: 0.0017, Accuracy: 92.55%\n",
            "Epoch 15: Test Loss: 0.0017, Accuracy: 92.67%\n",
            "Epoch 16: Test Loss: 0.0017, Accuracy: 92.74%\n",
            "Epoch 17: Test Loss: 0.0017, Accuracy: 92.73%\n",
            "Epoch 18: Test Loss: 0.0017, Accuracy: 92.67%\n",
            "Epoch 19: Test Loss: 0.0018, Accuracy: 92.69%\n",
            "Epoch 20: Test Loss: 0.0017, Accuracy: 92.99%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# GPU를 사용할 수 있으면 사용하고, 없으면 CPU 사용\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 이미지 데이터를 0~1로 정규화하고 텐서로 변환\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# FashionMNIST 데이터셋 불러오기 (훈련용, 테스트용 나눠서)\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 데이터 배치로 나눠서 로딩 (한 번에 128개씩 처리)\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
        "\n",
        "# CNN(합성곱 신경망) 모델 정의\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # 1채널 입력 이미지를 32채널로 변환 (3x3 필터, stride=1)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        # 32채널 이미지를 64채널로 변환\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        # 과적합 방지를 위해 일부 노드를 랜덤으로 꺼줌\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        # fully connected layer: conv에서 나온 결과를 일렬로 펼쳐 넣음\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10개의 옷 종류(클래스) 분류\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)          # 첫 번째 합성곱\n",
        "        x = nn.functional.relu(x) # 비선형 활성화(ReLU)\n",
        "        x = self.conv2(x)          # 두 번째 합성곱\n",
        "        x = nn.functional.relu(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)  # 2x2 최대풀링 (특징 압축)\n",
        "        x = self.dropout1(x)      # Dropout 적용\n",
        "        x = torch.flatten(x, 1)   # 1차원으로 펼치기\n",
        "        x = self.fc1(x)           # 첫 번째 완전 연결층\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.dropout2(x)      # Dropout 적용\n",
        "        x = self.fc2(x)           # 두 번째 완전 연결층 (최종 출력)\n",
        "        output = nn.functional.log_softmax(x, dim=1)  # softmax로 확률 변환\n",
        "        return output\n",
        "\n",
        "# 모델, 손실 함수, 최적화 알고리즘 설정\n",
        "model = CNNModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 학습할 epoch 수\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # 학습 모드 켜기\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()           # 이전 gradient 초기화\n",
        "        output = model(data)            # forward (예측값 계산)\n",
        "        loss = loss_fn(output, target)  # loss 계산\n",
        "        loss.backward()                 # gradient 계산\n",
        "        optimizer.step()                # 파라미터 업데이트\n",
        "\n",
        "    # 한 epoch이 끝나면 테스트 데이터로 성능 확인\n",
        "    model.eval()  # 평가 모드 켜기\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # gradient 계산 끄기 (메모리 절약, 속도 ↑)\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()  # batch별 loss 누적\n",
        "            pred = output.argmax(dim=1, keepdim=True)   # 예측 클래스 선택\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # 맞춘 개수 카운트\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}: Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}