1.
# import torch
# import torch.nn as nn
# import torch.nn.functional as F

# class MultivariateLinearRegressionModel(nn.Module):
#     def __init__(self):
#         super(MultivariateLinearRegressionModel, self).__init__()
#         self.linear = nn.Linear(3, 1)  # 입력값 3, 출력값 1로 설정

#     def forward(self, x):
#         return self.linear(x)

# # 학습 데이터 설정
# x_train = torch.FloatTensor([[80, 84, 89],
#                               [93, 88, 93],
#                               [89, 91, 90],
#                               [96, 98, 100],
#                               [73, 66, 70]])
# y_train = torch.FloatTensor([[160], [185], [180], [196], [142]])

# model = MultivariateLinearRegressionModel()

# optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)
# epoch = 10000

# # 손실 값 계산
# for i in range(epoch):
#     hy = model(x_train)

# ####################################################################
#     cost = F.mse_loss(hy, y_train)  # 손실 값을 간단한 코드로 대체 가능
    
#     optimizer.zero_grad()  # 로스값 초기화
#     cost.backward()  # 역전파
#     optimizer.step()  # 다시 학습(값 개선)

#     if i % 1000 == 0:
#         print('Epoch [{}/{}], Cost: {:.6f}'.format(i, epoch, cost.item()))


# ####################################################################
# #테스트

# test = torch.FloatTensor([[70, 80, 96]])
# prediction = model(test).item()  # 모델을 통한 예측
# print(prediction)


































2.


# import numpy as np
# import torch

# #선형 회귀 분석
# ##우리가 입력값, 출력 값 모두 값을 주고, 가장 평균이 되는 값을 예측하는 방법

# x_train=torch.FloatTensor([[5],[10],[15]])
# y_train=torch.FloatTensor([[10],[20],[30]]) 

# w=torch.zeros(1,requires_grad=True) #requires_grad=True는 우리가 학습할 것임을 암시/ 1은 출력 개수
# b=torch.zeros(1,requires_grad=True) 

#학습 데이터 설정
###################################################################
###################################################################
#실제 학습


# epoch = 1000 #반복학습 횟수

# for epoch in range(1, epoch):
#     hy=x_train * w + b ##우리가 구할 선형 회귀 식
    
#     ##로스 계산법: 표준편차 이용; 로스 가장 적게 조정하는 방식으로 b조정
#     cost=torch.mean((hy-y_train)**2)
    
#     optimizer = torch.optim.SGD([w,b],lr=0.005) ##영어 엘알임. 값 조정하면서 값 예측
#     ##SGD는 학습할 텐서, w변형 정도(작으면 속도가 느리고 크면 너무 크게 예측값을 바꿈)
    
#     optimizer.zero_grad() ##로스값 초기화
#     cost.backward() ##역전파
#     optimizer.step() ##다시 학습(값 개선)


# ######################################################################
# ######################################################################
# #테스트

# #그냥 답을 넣을수는 없고, 위처럼 값 대입해야 함

# test=torch.FloatTensor([6])
# prediction = w * test + b
# print(prediction.item()) ##html처럼 item()을 사용해 값만 출력함



































3.


# import torch
# import torch.nn as nn
# import torch.nn.functional as F

# class MultivariateLinearRegressionModel(nn.Module):
#     def __init__(self):
#         super(MultivariateLinearRegressionModel, self).__init__()
#         self.linear = nn.Linear(2, 1)  # 입력값 3, 출력값 1로 설정

#     def forward(self, x):
#         return self.linear(x)

# # 학습 데이터 설정
# x_train = torch.FloatTensor([[4.1, 7.8],
#         [0.3, 2.5],
#         [8.6, 1.3],
#         [5.2, 3.7],
#         [1.9, 5.9]])
# y_train = torch.FloatTensor([[27.3],
#         [5.9],
#         [29.2],
#         [24.3],
#         [19.0]])

# model = MultivariateLinearRegressionModel()

# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)
# epoch = 1000

# # 손실 값 계산
# for i in range(epoch):
#     hy = model(x_train)

# ####################################################################
#     cost = F.mse_loss(hy, y_train)  # 손실 값을 간단한 코드로 대체 가능
    
#     optimizer.zero_grad()  # 로스값 초기화
#     cost.backward()  # 역전파
#     optimizer.step()  # 다시 학습(값 개선)

#     if i % 100 == 0:
#         print('Epoch [{}/{}], Cost: {:.6f}'.format(i, epoch, cost.item()))


# ####################################################################
# #테스트

# test = torch.FloatTensor([[0.7, 4.1]])
# prediction = model(test)  # 모델을 통한 예측
# print(prediction.item())




